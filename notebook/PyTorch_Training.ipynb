{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z3sTIpoeNBF",
        "outputId": "8c9708d8-e051-4fda-ac3d-9eb91d34e1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  titanic.zip\n",
            "replace gender_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: gender_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "# Download titanic.zip from https://www.kaggle.com/competitions/titanic\n",
        "!unzip titanic.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from joblib import dump, load\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "TxW69h1-eThu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "USE_COLUMNS = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
        "MODEL_DIR = Path(\"models\")\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "BEST_MODEL_PATH = MODEL_DIR / \"mlp_torch_best.pth\"\n",
        "FINAL_MODEL_PATH = MODEL_DIR / \"mlp_torch_final.pth\"\n",
        "PREPROCESS_PATH = MODEL_DIR / \"preprocess.joblib\"\n",
        "THRESHOLD = 0.5\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_DIM = 32\n",
        "MAX_EPOCHS = 100\n",
        "PATIENCE = 10\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4"
      ],
      "metadata": {
        "id": "y8lNl8P5eUV0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "dpEmQc5LeVYQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = pl.read_csv(\"train.csv\").select(USE_COLUMNS + [\"Survived\"])\n",
        "test_raw = pl.read_csv(\"test.csv\").select(USE_COLUMNS)"
      ],
      "metadata": {
        "id": "h2kX37b3eWOa"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess\n",
        "Encoding string categorical feature(`Sex` column) to labels.\n",
        "\n",
        "- `female`: 0\n",
        "- `male`: 1"
      ],
      "metadata": {
        "id": "jZu0xkPwwp7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sex_label_mapping = {\"female\": 0, \"male\": 1}\n",
        "train_numeric = train_raw.with_columns(\n",
        "    pl.col(\"Sex\").replace_strict(sex_label_mapping).alias(\"Sex\")\n",
        ")\n",
        "test_numeric = test_raw.with_columns(\n",
        "    pl.col(\"Sex\").replace_strict(sex_label_mapping).alias(\"Sex\")\n",
        ")"
      ],
      "metadata": {
        "id": "0T4v6NhFebaj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting training dataset for validation."
      ],
      "metadata": {
        "id": "Ci5L_slTxA_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid = train_test_split(train_numeric, test_size=0.3, random_state=SEED)\n",
        "print(f\"train size: {train.shape}\")\n",
        "print(f\"valid size: {valid.shape}\")\n",
        "\n",
        "y_train = train[\"Survived\"].to_numpy()\n",
        "y_valid = valid[\"Survived\"].to_numpy()\n",
        "X_train = train.select(pl.exclude(\"Survived\"))\n",
        "X_valid = valid.select(pl.exclude(\"Survived\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y78lSs0YfGmK",
        "outputId": "fbd405b1-e0ec-4634-a6d5-7f181d80e196"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: (623, 7)\n",
            "valid size: (268, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_np = X_train.to_numpy()\n",
        "X_valid_np = X_valid.to_numpy()\n",
        "\n",
        "X_train_np = imputer.fit_transform(X_train_np)\n",
        "X_valid_np = imputer.transform(X_valid_np)\n",
        "\n",
        "X_train_np = scaler.fit_transform(X_train_np)\n",
        "X_valid_np = scaler.transform(X_valid_np)"
      ],
      "metadata": {
        "id": "UfB6z3ezfHvx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct as DataLoader\n",
        "Xtr = torch.tensor(X_train_np, dtype=torch.float32)\n",
        "ytr = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
        "Xva = torch.tensor(X_valid_np, dtype=torch.float32)\n",
        "yva = torch.tensor(y_valid.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=BATCH_SIZE, shuffle=True)\n"
      ],
      "metadata": {
        "id": "0dWnbmr6fI_X"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 layer NN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_dim: int, hid_dim: int):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hid_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hid_dim, 1)  # binary logit\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)  # logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "qqSWrTnefJ7T"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = Xtr.shape[1]\n",
        "model = Net(input_dim, HIDDEN_DIM)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
      ],
      "metadata": {
        "id": "YAQBC3o6fLbz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "F9fP0jlR01mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = float(\"inf\")\n",
        "wait = 0\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * xb.size(0)\n",
        "    epoch_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_logits = model(Xva)\n",
        "        val_loss = criterion(val_logits, yva).item()\n",
        "        pred_label = (val_logits > 0.5).to(int)\n",
        "        score = f1_score(pred_label, yva, average='macro')\n",
        "    print(f\"Epoch {epoch:03d} | train_loss={epoch_loss:.4f} val_loss={val_loss:.4f} f1-score={score:.4f}\")\n",
        "\n",
        "    if val_loss + 1e-6 < best_val:\n",
        "        best_val = val_loss\n",
        "        wait = 0\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= PATIENCE:\n",
        "            print(\"Early stopping.\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u08tAQ_zfMsT",
        "outputId": "be7a1bb6-4653-442a-af61-664c7bfd76bb"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | train_loss=0.6900 val_loss=0.6803 f1-score=0.3776\n",
            "Epoch 002 | train_loss=0.6693 val_loss=0.6600 f1-score=0.3776\n",
            "Epoch 003 | train_loss=0.6500 val_loss=0.6412 f1-score=0.3694\n",
            "Epoch 004 | train_loss=0.6323 val_loss=0.6240 f1-score=0.3694\n",
            "Epoch 005 | train_loss=0.6162 val_loss=0.6073 f1-score=0.3694\n",
            "Epoch 006 | train_loss=0.6002 val_loss=0.5921 f1-score=0.3694\n",
            "Epoch 007 | train_loss=0.5864 val_loss=0.5770 f1-score=0.3889\n",
            "Epoch 008 | train_loss=0.5725 val_loss=0.5630 f1-score=0.4059\n",
            "Epoch 009 | train_loss=0.5600 val_loss=0.5494 f1-score=0.4309\n",
            "Epoch 010 | train_loss=0.5482 val_loss=0.5365 f1-score=0.4649\n",
            "Epoch 011 | train_loss=0.5374 val_loss=0.5242 f1-score=0.5125\n",
            "Epoch 012 | train_loss=0.5271 val_loss=0.5131 f1-score=0.5566\n",
            "Epoch 013 | train_loss=0.5185 val_loss=0.5025 f1-score=0.6077\n",
            "Epoch 014 | train_loss=0.5100 val_loss=0.4926 f1-score=0.6266\n",
            "Epoch 015 | train_loss=0.5022 val_loss=0.4837 f1-score=0.6478\n",
            "Epoch 016 | train_loss=0.4954 val_loss=0.4757 f1-score=0.6590\n",
            "Epoch 017 | train_loss=0.4891 val_loss=0.4685 f1-score=0.6979\n",
            "Epoch 018 | train_loss=0.4837 val_loss=0.4617 f1-score=0.7209\n",
            "Epoch 019 | train_loss=0.4785 val_loss=0.4561 f1-score=0.7427\n",
            "Epoch 020 | train_loss=0.4742 val_loss=0.4504 f1-score=0.7623\n",
            "Epoch 021 | train_loss=0.4699 val_loss=0.4456 f1-score=0.7671\n",
            "Epoch 022 | train_loss=0.4665 val_loss=0.4412 f1-score=0.7859\n",
            "Epoch 023 | train_loss=0.4629 val_loss=0.4376 f1-score=0.7870\n",
            "Epoch 024 | train_loss=0.4599 val_loss=0.4346 f1-score=0.7834\n",
            "Epoch 025 | train_loss=0.4571 val_loss=0.4317 f1-score=0.8114\n",
            "Epoch 026 | train_loss=0.4546 val_loss=0.4294 f1-score=0.8114\n",
            "Epoch 027 | train_loss=0.4523 val_loss=0.4272 f1-score=0.8078\n",
            "Epoch 028 | train_loss=0.4500 val_loss=0.4248 f1-score=0.8006\n",
            "Epoch 029 | train_loss=0.4481 val_loss=0.4229 f1-score=0.8006\n",
            "Epoch 030 | train_loss=0.4463 val_loss=0.4215 f1-score=0.8006\n",
            "Epoch 031 | train_loss=0.4446 val_loss=0.4206 f1-score=0.8006\n",
            "Epoch 032 | train_loss=0.4429 val_loss=0.4196 f1-score=0.8006\n",
            "Epoch 033 | train_loss=0.4412 val_loss=0.4189 f1-score=0.7970\n",
            "Epoch 034 | train_loss=0.4400 val_loss=0.4182 f1-score=0.7970\n",
            "Epoch 035 | train_loss=0.4384 val_loss=0.4176 f1-score=0.7970\n",
            "Epoch 036 | train_loss=0.4370 val_loss=0.4170 f1-score=0.7970\n",
            "Epoch 037 | train_loss=0.4358 val_loss=0.4164 f1-score=0.8006\n",
            "Epoch 038 | train_loss=0.4346 val_loss=0.4158 f1-score=0.8006\n",
            "Epoch 039 | train_loss=0.4334 val_loss=0.4154 f1-score=0.8006\n",
            "Epoch 040 | train_loss=0.4324 val_loss=0.4152 f1-score=0.8006\n",
            "Epoch 041 | train_loss=0.4313 val_loss=0.4150 f1-score=0.8006\n",
            "Epoch 042 | train_loss=0.4302 val_loss=0.4145 f1-score=0.8006\n",
            "Epoch 043 | train_loss=0.4293 val_loss=0.4144 f1-score=0.7953\n",
            "Epoch 044 | train_loss=0.4282 val_loss=0.4142 f1-score=0.7962\n",
            "Epoch 045 | train_loss=0.4273 val_loss=0.4141 f1-score=0.7909\n",
            "Epoch 046 | train_loss=0.4264 val_loss=0.4138 f1-score=0.7909\n",
            "Epoch 047 | train_loss=0.4257 val_loss=0.4136 f1-score=0.7909\n",
            "Epoch 048 | train_loss=0.4246 val_loss=0.4133 f1-score=0.7909\n",
            "Epoch 049 | train_loss=0.4239 val_loss=0.4131 f1-score=0.7909\n",
            "Epoch 050 | train_loss=0.4232 val_loss=0.4129 f1-score=0.7945\n",
            "Epoch 051 | train_loss=0.4224 val_loss=0.4128 f1-score=0.7909\n",
            "Epoch 052 | train_loss=0.4218 val_loss=0.4130 f1-score=0.7971\n",
            "Epoch 053 | train_loss=0.4210 val_loss=0.4132 f1-score=0.7777\n",
            "Epoch 054 | train_loss=0.4203 val_loss=0.4128 f1-score=0.7980\n",
            "Epoch 055 | train_loss=0.4195 val_loss=0.4128 f1-score=0.7971\n",
            "Epoch 056 | train_loss=0.4190 val_loss=0.4128 f1-score=0.7777\n",
            "Epoch 057 | train_loss=0.4184 val_loss=0.4128 f1-score=0.7730\n",
            "Epoch 058 | train_loss=0.4177 val_loss=0.4126 f1-score=0.7971\n",
            "Epoch 059 | train_loss=0.4173 val_loss=0.4127 f1-score=0.7587\n",
            "Epoch 060 | train_loss=0.4167 val_loss=0.4128 f1-score=0.7766\n",
            "Epoch 061 | train_loss=0.4158 val_loss=0.4128 f1-score=0.7623\n",
            "Epoch 062 | train_loss=0.4152 val_loss=0.4128 f1-score=0.7623\n",
            "Epoch 063 | train_loss=0.4150 val_loss=0.4127 f1-score=0.7658\n",
            "Epoch 064 | train_loss=0.4141 val_loss=0.4128 f1-score=0.7623\n",
            "Epoch 065 | train_loss=0.4138 val_loss=0.4131 f1-score=0.7610\n",
            "Epoch 066 | train_loss=0.4131 val_loss=0.4132 f1-score=0.7561\n",
            "Epoch 067 | train_loss=0.4127 val_loss=0.4134 f1-score=0.7561\n",
            "Epoch 068 | train_loss=0.4120 val_loss=0.4132 f1-score=0.7561\n",
            "Early stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load best & save final\n",
        "model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=\"cpu\"))\n",
        "torch.save(model.state_dict(), FINAL_MODEL_PATH)\n",
        "dump({\"imputer\": imputer, \"scaler\": scaler}, PREPROCESS_PATH)\n",
        "print(\"Saved model & preprocessors:\", FINAL_MODEL_PATH, PREPROCESS_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Ll5IP3fOWf",
        "outputId": "7c679b5c-8666-4151-cb00-62e0c1e4f010"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model & preprocessors: models/mlp_torch_final.pth models/preprocess.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# Inference utilities (前処理の読み込み → sigmoid(model(x)) → しきい値でラベル化)\n",
        "# =====================================================================\n",
        "def load_preprocess_and_model(model_path=FINAL_MODEL_PATH, preprocess_path=PREPROCESS_PATH,\n",
        "                              input_dim_hint=None, hidden_dim=HIDDEN_DIM):\n",
        "    \"\"\"前処理(imputer, scaler)と学習済みモデルを読み込み\"\"\"\n",
        "    pp = load(preprocess_path)  # {\"imputer\": ..., \"scaler\": ...}\n",
        "    imputer_loaded = pp[\"imputer\"]\n",
        "    scaler_loaded = pp[\"scaler\"]\n",
        "\n",
        "    # input_dim は呼び出し時のデータから決まるが、クラス定義には必要\n",
        "    in_dim = input_dim_hint if input_dim_hint is not None else input_dim\n",
        "    mdl = Net(in_dim, hidden_dim)\n",
        "    mdl.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "    mdl.eval()\n",
        "    return imputer_loaded, scaler_loaded, mdl"
      ],
      "metadata": {
        "id": "AUX0QxsqfSfh"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba_numpy(X_np: np.ndarray, imputer: SimpleImputer, scaler: StandardScaler, mdl: nn.Module) -> np.ndarray:\n",
        "    \"\"\"確率（正例=1の確率）を numpy で返す\"\"\"\n",
        "    X_tx = imputer.transform(X_np)\n",
        "    X_tx = scaler.transform(X_tx)\n",
        "    Xt = torch.tensor(X_tx, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        prob = torch.sigmoid(mdl(Xt)).numpy().ravel()\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "RemUt933fTi2"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label_numpy(X_np: np.ndarray, imputer: SimpleImputer, scaler: StandardScaler, mdl: nn.Module,\n",
        "                        threshold: float = THRESHOLD) -> np.ndarray:\n",
        "    \"\"\"確率を閾値で 0/1 に変換\"\"\"\n",
        "    prob = predict_proba_numpy(X_np, imputer, scaler, mdl)\n",
        "    return (prob > threshold).astype(int)"
      ],
      "metadata": {
        "id": "E2AkmyzqfV7E"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Example: run inference on test.csv\n",
        "# ----------------------\n",
        "# 前処理：Sexエンコード（学習と同じ変換）\n",
        "test_np = test_numeric.to_numpy()\n",
        "\n",
        "# 読み込み（input_dim_hint は列数を指定）\n",
        "imputer_ld, scaler_ld, model_ld = load_preprocess_and_model(\n",
        "    model_path=FINAL_MODEL_PATH,\n",
        "    preprocess_path=PREPROCESS_PATH,\n",
        "    input_dim_hint=test_np.shape[1],\n",
        "    hidden_dim=HIDDEN_DIM\n",
        ")\n",
        "\n",
        "test_prob = predict_proba_numpy(test_np, imputer_ld, scaler_ld, model_ld)\n",
        "test_pred = (test_prob > THRESHOLD).astype(int)\n",
        "\n",
        "print(\"test prob head:\", test_prob[:10])\n",
        "print(\"test pred head:\", test_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCnGQLylfWhL",
        "outputId": "fb6f9828-8342-4545-bfab-529b5cd293c6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test prob head: [0.08423626 0.44779164 0.09385546 0.11689068 0.59219176 0.18823364\n",
            " 0.62022376 0.28163928 0.6368817  0.1932441 ]\n",
            "test pred head: [0 0 0 0 1 0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_model = torch.compile(model)"
      ],
      "metadata": {
        "id": "W_gYwdb2fYHI"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gQIf8PZi6xO",
        "outputId": "6d0e9d27-3da3-40fc-f46e-d8f482de38cb"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDLFKndFjBoE",
        "outputId": "9a755c3c-93cd-48e4-f91d-1b632fa92510"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): Net(\n",
              "    (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade onnx onnxscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNWau0wOow6D",
        "outputId": "6c4f82f6-f8cb-4f94-fe58-c35911c27017"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.19.1)\n",
            "Requirement already satisfied: onnxscript in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Requirement already satisfied: onnx_ir<2,>=0.1.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.1.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx"
      ],
      "metadata": {
        "id": "SbGLmg3GjIFM"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, input_dim)\n",
        "\n",
        "onnx_program = torch.onnx.export(model, dummy_input, dynamo=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdil1F_8nA-p",
        "outputId": "7c0caf93-58d7-4f03-a290-af8dd80c437c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `Net([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `Net([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_program.save(MODEL_DIR / \"mlp_torch.onnx\")"
      ],
      "metadata": {
        "id": "MABHzrNXou5B"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ed9Ac3ERpS62"
      },
      "execution_count": 93,
      "outputs": []
    }
  ]
}